{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie\n",
    "\n",
    "Przed rozpoczęciem pracy z notatnikiem proszę zmienić jego nazwę dodając na początku numer albumu, imię i nazwisko.\n",
    "{nr_albumu}\\_{imię}\\_{nazwisko}\\_{nazwa}\n",
    "\n",
    "Po wykonaniu wszystkich zadań proszę przesłać wypełniony notatnik przez platformę ELF za pomocą formularza \"Prześlij projekt\" w odpowiedniej sekcji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja liniowa prosta\n",
    "\n",
    "Regresja liniowa prosta, to szczególny przypadek regresji liniowej, w którym zmienną objaśnaną przewidujemy za pomocą jednej zmiennej objaśniającej. Zadanie będzie polegało na wyznaczeniu funkcji regresji opisującej zależność zarobków od lat doświadczenia. \n",
    "\n",
    "Zbiór danych do tego zadania, to Salary.csv. Znajduje się w katalogu datasets.\n",
    "W zbiorze danych znajduje się 35 obserwacji. Każdy wpis jest osobną obserwacją. W zbiorze znajdują się 3 kolumny: YearsExperience, Age i Salary. W pierwszym zadaniu należy wykorzystać YearsExperience i Salary, pomijając Age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "\n",
    "Wczytaj dane z pliku Salary.csv, a następnie stwórz wykres przedstawiający obserwacje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'X')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('datasets/Salary.csv', sep=',')\n",
    "x = df['YearsExperience'].values.reshape(df['YearsExperience'].shape[0], 1)\n",
    "y = df['Salary'].values.reshape(df['Salary'].shape[0], 1)\n",
    "# YOUR CODE HERE\n",
    "plt.scatter(x,y)\n",
    "plt.ylabel(\"Y\")\n",
    "plt.xlabel(\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "\n",
    "Implementacja algorytmu regresji liniowej prostej.\n",
    "\n",
    "Żeby dobrze zrozumieć zapis matematyczny, który początkowo może sprawiać problemy, przejdziemy po kolei po elementach składowych algorytmu. Następnie złączymy elementy w całość.\n",
    "\n",
    "Wzór na regresję liniową w naszym przypadku będzie wyglądał następująco:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x^{(i)}) = \\beta_{0} + \\beta_{1}x_1 = \\beta_{0} + \\beta_{1}  YearsExperience\n",
    "\\end{equation}\n",
    "\n",
    "Przypomnijmy, że zapis $x^{(i)}$ oznacza wektor dla $i$-tej obserwacji. W naszym przypadku ten wektor będzie zawierał tylko $1$ wartość dla cechy $YearsExperience$.\n",
    "\n",
    "\n",
    "_Uwaga: W różnych źródłach algorytm regresji liniowej ma różne zapisy. Czasem podawane są wzory w postaci z sumą, czasem w postaci macierzowej. Jest to spowodowane tym, że algorytm można zaimplementować na te dwa sposoby. Łatwiejszym i bardziej intuicyjnym podejściem jest podejście z sumą, która bezpośrednio sugeruje wykokrzystanie pętli w celu iteracji po obserwacjach/cechach. Implementacja z wykorzystaniem macierzy jest zwykle krótsza i \"bardziej elegancka\", ale również bardziej wydajna. Aby dobrze zrozumieć działanie algorytmu, najlepiej jest zaimplementować obie wersje i porównać je ze sobą._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Inicjalizacja współczynników $\\beta$ regresji\n",
    "\n",
    "Pierwszym krokiem jest inicjalizacja współczynników regresji. W przypadku regresji liniowej prostej mamy dwa współczynniki $\\beta_{0}$ i $\\beta_{1}$. Stwórz dwie zmienne będące współczynnikami regresji liniowej prostej i zainicjalizuj je losowymi wartościami z przedziału $(0,1)$.\n",
    "\n",
    "Dodatkowo stwórz zmienną *alpha*, która przyjmie wartość od $(0,1)$. Możesz ustawić ją ręcznie i sprawdzać jak różne wartości mają wpływ na regresję. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import random\n",
    "beta_0 = random.random()\n",
    "beta_1 = random.random()\n",
    "alpha = 0.15 # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Obliczenie predykcji\n",
    "\n",
    "Kolejnym krokiem jest obliczenie wartości funkcji regresji dla wszystkich obserwacji w zbiorze danych. Jest to po prostu wstawienie kolejnych wartości pod wzrór regresji.\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\beta_{0} + \\beta_{1}x_1\n",
    "\\end{equation}\n",
    "\n",
    "Można zrobić to z wykorzystaniem operacji na macierzach (wektorach), albo z wykorzystaniem klasycznej iteracji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def prediction(beta_0,beta_1) : return beta_0 + beta_1*x.sum()\n",
    "\n",
    "#beta_0 +beta_1*x return array - usef for matrix solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Obliczenie błędu\n",
    "\n",
    "Obliczenie wartości błędu regresji nie jest konieczne do aktualizacji wag, jednak jest to bardzo cenna informacja czy nasz algorytm działa poprawnie. Wartość błędu nie może rosnąć w kolejnych epokach.\n",
    "\n",
    "Błąd należy obliczyć zgodnie ze wzorem:\n",
    "\n",
    "\\begin{equation}\n",
    "    SSR = \\frac{1}{2m} \\sum_{i=1}^{m}(f(x^{(i)}) - y^{(i)})^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123139865098.11276"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f(x) = \n",
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "SSR = 0.0\n",
    "b_0 = random.random()\n",
    "b_1 = random.random()\n",
    "SSR += (prediction(b_0,b_1) - y.sum())**2\n",
    "SSR = SSR /(2*len(x))\n",
    "SSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Obliczenie gradientu \n",
    "\n",
    "Żeby obliczyć gradient, należy obliczyć pochodne cząstkowe względem parametrów $\\beta_{0}$ i $\\beta_{1}$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial SSR}{\\partial \\beta_{0}} = \\frac{1}{m} \\sum^{m}_{i=1} (f(x^{(i)}) - y^{(i)})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial SSR}{\\partial \\beta_{1}} = \\frac{1}{m} \\sum^{m}_{i=1} (f(x^{(i)}) - y^{(i)})x_{1}^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "Tutaj ponownie jak wcześniej można wykorzystać operacje na macierzach, lub iteracyjnie obliczyć sumę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-83887.82013721897 -76261.65467019906\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def gradient_0():\n",
    "    grad_0 = 0\n",
    "    grad_0 += (prediction(beta_0,beta_1) -y.sum())\n",
    "    grad_0 = grad_0/len(x)\n",
    "    return grad_0\n",
    "\n",
    "def gradient_1():\n",
    "    grad_1 = 0\n",
    "    grad_1 += (prediction(beta_0,beta_1) -y.sum())\n",
    "    grad_1 = grad_1/(len(x)*x[0,0])\n",
    "    return grad_1\n",
    "\n",
    "print(gradient_0(),gradient_1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.5 Aktualizacja współczynników regresji (wag)\n",
    "\n",
    "Po obliczeniu pochodnych cząstkowych należy obliczyć nowe wartości dla współczynników regresji.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\beta_{0} = \\beta_{0} - \\alpha \\frac{\\partial SSR}{\\partial \\beta_{0}} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\beta_{1} = \\beta_{1} - \\alpha \\frac{\\partial SSR}{\\partial \\beta_{1}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14334.547728670961 12975.16812020132\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "beta_0 = beta_0 - gradient_0()* alpha \n",
    "\n",
    "beta_1 = beta_1 - gradient_1() * alpha \n",
    "\n",
    "print(beta_0,beta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Finalna wersja algorytmu\n",
    "\n",
    "Powyższe działania, to wszystkie elementy potrzebne do stworzenia algorytmu regresji liniowej prostej. Jeden cykl takich operacji nazywany jest **epoką**. Idea obliczania współczynników regresji z wykorzystaniem gradientu polega na iteracyjnym aktualizowaniu współczynników do momentu, aż błąd przestanie znacznie się zmieniać. Można również ustawić jakaś stałą ilość epok. W każdej epoce wykorzystuje się ponownie ten sam zestaw danych.\n",
    "\n",
    "Skoro wiadomo już jakie pojedyncze etapy należy wykonać, żeby obliczyć regresję liniową prostą, przyszedł czas na zebranie wszystkiego w jednym miejscu.\n",
    "\n",
    "Proszę zaimplementować funkcję `learn_and_fit(x, y)`, która dla danych wejściowych będzie zwracać współczynniki regresji w każdej z epok. Dodatkowo proszę zwracać również błąd regresji w każdej epoce. Funkcja może być zaimplementowana w dowolny sposób. Może bezpośrednio zawierać wszystkie instrukcje, może korzystać z innych funkcji pomocniczych albo może korzystać z klasy reprezentującą regresję liniową prostą. \n",
    "\n",
    "Na końcu notebooka znajduje się test jednostkowy, który musi przechodzić przy prawidłowej implementacji algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input:\n",
    "x - wartości zmiennej objaśniającej YearsExperience dla wszystkich obserwacji\n",
    "y - wartości zmiennej objaśnianej Salary dla wszystkich obserwacji\n",
    "\n",
    "output:\n",
    "b0: [] - lista z współczynnikami beta_0 w każdej z epok\n",
    "b1: [] - lista z współczynnikami beta_1 w każdej z epok\n",
    "error: [] - lista z błędem w każdej epoce\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "def learn_and_fit(x, y):\n",
    "    import random\n",
    "    beta_0 = random.random()\n",
    "    beta_1 = random.random()\n",
    "    alpha = 0.01\n",
    "    b0 = [beta_0]\n",
    "    b1 = [beta_1]\n",
    "    error = []\n",
    "    for epoch in range(1000):#1000 epok\n",
    "        SSR = 0 \n",
    "        SSR += (prediction(beta_0,beta_1) - y.sum())**2\n",
    "        SSR=SSR/((len(x))*2)\n",
    "        error.append(SSR)\n",
    "\n",
    "        g_0 , g_1 = gradient_0() , gradient_1()\n",
    "        beta_0 = beta_0 - g_0) * alpha \n",
    "        beta_1 = beta_1 - g_1 * alpha \n",
    "        \n",
    "        b0.append(beta_0)\n",
    "        b1.append(beta_1)\n",
    "    \n",
    "\n",
    "    \n",
    "    return b0, b1, error\n",
    "b0, b1, error = learn_and_fit(x, y)\n",
    "print(error[0],error[-1])\n",
    "print(beta_1,beta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "\n",
    "Do wykresu stworzonego w zadaniu 1 dodaj prostą regresji. Stwórz 3 wykresy przedstawiające jak zmieniała się funkcja regresji na przestrzeni epok (pierwsza, środokowa, ostatnia epoka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HEREimport pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('datasets/Salary.csv', sep=',')\n",
    "x = df['YearsExperience'].values.reshape(df['YearsExperience'].shape[0], 1)\n",
    "y = df['Salary'].values.reshape(df['Salary'].shape[0], 1)\n",
    "# YOUR CODE HERE\n",
    "b0, b1, error = learn_and_fit(x, y)\n",
    "#plt.scatter(x,y)\n",
    "#plt.plot(x,b0[0] + b1[0]*x+error[0])\n",
    "#plt.plot(x,b0[len(b0)//2] + b1[len(b0)//2]*x + error[len(b0)//2])\n",
    "plt.plot(x,b0[-1] + b1[-1]*x + error[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy jednostkowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_learn_and_fit (__main__.SimpleLinearRegressionTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_learn_and_fit (__main__.SimpleLinearRegressionTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Galax\\AppData\\Local\\Temp/ipykernel_768/2507244529.py\", line 16, in test_learn_and_fit\n",
      "    self.assertTrue(all(i >= j for i, j in zip(error, error[1:]))) #Sprawdzenie, czy błędy nie rosną\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.166s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x25370309790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "\n",
    "class SimpleLinearRegressionTest(unittest.TestCase):\n",
    "    \n",
    "    def test_learn_and_fit(self):\n",
    "        df = pd.read_csv('datasets/Salary.csv', sep=',')\n",
    "        x = df['YearsExperience'].values.reshape(df['YearsExperience'].shape[0], 1)\n",
    "        y = df['Salary'].values.reshape(df['Salary'].shape[0], 1)\n",
    "        \n",
    "        b0, b1, error = learn_and_fit(x, y)\n",
    "        \n",
    "        self.assertTrue(len(b0) > 1)\n",
    "        self.assertTrue(len(b1) > 1)\n",
    "        self.assertTrue(len(b0) == len(b1))\n",
    "        self.assertTrue(all(i >= j for i, j in zip(error, error[1:]))) #Sprawdzenie, czy błędy nie rosną\n",
    "        \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
